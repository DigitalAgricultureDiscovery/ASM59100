{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Jyw53p8CdfN"
      },
      "source": [
        "# CGT57500 / ASM 59100 - Edge Device Lab 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haQLlslhCdfS"
      },
      "source": [
        "# Deep Learning-Based Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDgqqc9_CdfT"
      },
      "source": [
        "### 1. Introduction \n",
        "Deep learning (DL) is a subset of machine learning (ML) which is a subset of artificial intellignece (AI). DL uses convolutional neural networks (CNN)s to extract important features from particular datasets that used to train models for learning specific patterns. One of the most popular and widely used applications of deep learning is image classification. Image classification refers to the identification of different objects that are represented within images. DL-based image classification models require large datasets with hundereds of thousands of images for learning features accurately. \n",
        "<!-- \n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1Lz9plj4xJY9rxvlFsw-DT4SI0IE-5r3J\" width=300/> -->\n",
        "\n",
        "In order to train image classification models, a dataset comprised of different classes is first provided. Each class consists of hunderds to thousands of images. As the number of images used for training image classification models increases, CNN can help train the models better, resulting in higher accuracies. One of the most popular dataset in the MNIST dataset consisting of 10 classes for the numbers 0 to 9. Each class consists of multiple images. In addition, \"Fashion MNIST\" is another popular dataset that is commonly used as a benchmast. Both of these datasets will be used in this lab for training deep learning models capable of identifying the classes present in each of these datasets.\n",
        "\n",
        "The image below shows how a sliding window moves across an image to learn specific features using CNNs.\n",
        "\n",
        "<!-- <img src=\"img/cnn1.gif\" width=300 height=300 />      -->\n",
        "\n",
        "### 2. Language and Framework\n",
        "There are multiple different programming languages and frameworks that are used for training deep learning models. Python is currently the most popular programming language that is used. In addition, two common frameworks are used, namely TensorFlow and PyTorch. However, as TesnorFlow was first introduced, it is more commonly used with a larger community for support. Keras is a framework that is built on top of TensorFlow which helped to easily implement deep learning. Therefore, for the purpose of this lab, Keras and TensorFlow will be used. \n",
        "\n",
        "<!-- <img src=\"img/keras.jpg\" width=500 height=200 /> -->\n",
        "\n",
        "### 3. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVet7LfZCdfX"
      },
      "outputs": [],
      "source": [
        "# first import the tensorflow and keras libraries\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdNU2iN0CdfY"
      },
      "outputs": [],
      "source": [
        "# import additional libraries for arrays and plotting\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import additional libraries\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.utils import img_to_array, array_to_img\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "bruFIzJh0C-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiou_acJCdfZ"
      },
      "source": [
        "### 4. Import Dataset\n",
        "The \"MNIST\" and \"Fashion MNIST\" datasets are benchmark datasets that avaialble to download from tensorflow. Run the code block below in order to obtain the dataset in the correct format. The images below  shows how CNN's learn important features from the MNIST dataset.\n",
        "\n",
        "<!-- <img src=\"img/cnn2.gif\" width=300 height=300 /> -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUhLn5SVCdfb"
      },
      "outputs": [],
      "source": [
        "# import the MNIST dataset\n",
        "(x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbZvy7JmCdfc"
      },
      "outputs": [],
      "source": [
        "# print the shape of the dataset\n",
        "x_train_mnist.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSQOjOeZCdfd"
      },
      "source": [
        "After displaying the shape of the training dataset, you will see (60000,28,28). Here, 60000 represents the number of images that are present and 28 represents that the width and the height of the images is 28 (28 x 28 pixels).\n",
        "\n",
        "However, we will not be able to use the dataset with this shape. Therefore, it needs to be resized and normailized. This is because, in the Keras and Tensorflow frameworks, the input needs to be in an array of 4 dimensions while we currently have 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0o6yHyvCdfe"
      },
      "outputs": [],
      "source": [
        "# Resize and Normalize the dataset in order to prepare it for training a deep learning model\n",
        "x_train_mnist = x_train_mnist.reshape(60000, 28, 28, 1) # the training set is resized and 60000 represents the number of training images\n",
        "x_test_mnist = x_test_mnist.reshape(10000, 28, 28, 1) # the testing set is resized and 10000 represents the number of training images\n",
        "input_shape = (28,28,1) # this is the input shape for each of the image that will be used for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxIOi_Q2Cdff"
      },
      "outputs": [],
      "source": [
        "y_train_mnist.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U_Z_4TlCdfg"
      },
      "source": [
        "y_train_mnist and y_test_mnist simply represent the labels for each of the image that is present. Therefore, these don't need to be resized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9ti0FKQCdfg"
      },
      "source": [
        "### 5. Build Model Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8y9p_OTZCdfg"
      },
      "outputs": [],
      "source": [
        "# Build the Neural Network Model Architecture\n",
        "\n",
        "model = tf.keras.Sequential() # use sequential to initialize the model before adding layers\n",
        "\n",
        "''' Convolutional Layer 1 '''\n",
        "# we will add our first convolutional layer\n",
        "model.add(Conv2D(64,  # The first layer has 64 filters\n",
        "                (3,3),  # This is the kernel size which represents the size of the convolution window. We will use 3 x 3 convolution.\n",
        "                activation='relu',  # This is the RELU activation function. RELU is commonly used in all the convolutional layers.\n",
        "                input_shape=input_shape))  # The input shape is only provided to the first layer in the architecture and the following layers will automatically use this. Based on our dataset, this is (28,28,1)\n",
        "\n",
        "\n",
        "# each convolutional layer is followed by a maxpooling layer\n",
        "model.add(MaxPooling2D(2,2))  # We will use MaxPooling 2 x 2. This helps combine features in differnet parts of the image.\n",
        "\n",
        "\n",
        "# add a few more convolutional layers with reduced number of nodes.\n",
        "''' Convolutional Layer 2 '''\n",
        "model.add(Conv2D(32,  # The second layer has 32 filters.\n",
        "                (3,3),  # This is the kernel size which represents the size of the convolution window. We will use 3 x 3 convolution.\n",
        "                activation='relu'))  # This is the RELU activation function. RELU is commonly used in all the convolutional layers.\n",
        "\n",
        "# each convolutional layer is followed by a maxpooling layer\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "''' Convolutional Layer 3 '''\n",
        "model.add(Conv2D(16,  # The second layer has 16 filters.\n",
        "                (3,3),  # This is the kernel size which represents the size of the convolution window. We will use 3 x 3 convolution.\n",
        "                activation='relu'))  # This is the RELU activation function. RELU is commonly used in all the convolutional layers.\n",
        "\n",
        "# each convolutional layer is followed by a maxpooling layer\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "''' Flatten '''\n",
        "# after adding all the convolutional layers, we have to flatten the network in order to make predictions and assign classes\n",
        "model.add(Flatten())  # flatten will convert the 2D network into a 1D network \n",
        "\n",
        "''' Dense Layer 1 '''\n",
        "# after the architecture is flattened, we have to add fully convolutional layers or dense layers\n",
        "model.add(Dense(128,  # The dense layer has 128 filters\n",
        "               activation='relu'))  # This is the RELU activation function\n",
        "\n",
        "''' Dense Layer 2 / Final Output Layer '''\n",
        "# finally, we add the output layer where the activation function must be a softmax and the number of nodes must be equal to the number of classes\n",
        "model.add(Dense(10,  # The final output layer has 10 filters which corresponds to the 10 different classes that we are going to be classifying\n",
        "               activation='softmax'))  # This is the Softmax activation function which is necessary in the final output layer for multi-class classification problems. Softmax provides a probability for each class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hqYiDLWCdfh"
      },
      "outputs": [],
      "source": [
        "# show the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vVYvEozCdfk"
      },
      "source": [
        "### 6. Set The Hyperparameters and Train The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKGQ9-GRCdfm"
      },
      "outputs": [],
      "source": [
        "# Compile the Model\n",
        "model.compile(optimizer='adam',  # We will be using the Adam optimizer. This is useful and has proven effective for multiclass classification problems.\n",
        "              loss='sparse_categorical_crossentropy',  # We will use the categorical crossentropy loss function. The loss function helps the different filters update weights to learn features from data.\n",
        "              metrics=['accuracy'])  # While training the model, this line will hep keep track of the accuracy.\n",
        "\n",
        "# Train the Model\n",
        "history = model.fit(x=x_train_mnist, y=y_train_mnist, validation_data=(x_test_mnist, y_test_mnist), epochs=10)\n",
        "# x represents the training data\n",
        "# y represnets the training labels\n",
        "# validation data requires (testing data, testing labels)\n",
        "# we train the model for 10 epochs which means that the model will go over the entire dataset 10 times to learn and confirm model training performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxDKKYpACdfn"
      },
      "source": [
        "### 7. Evaluate The Model and Visualize The Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgdXdq_NCdfo"
      },
      "outputs": [],
      "source": [
        "# Evaluate the Model\n",
        "\n",
        "# print out the testing accuracy\n",
        "model.evaluate(x_test_mnist, y_test_mnist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXKcYE-KCdfq"
      },
      "outputs": [],
      "source": [
        "# shown an example image and pass it into the model\n",
        "image_index = 4444\n",
        "plt.imshow(x_test_mnist[image_index].reshape(28, 28),cmap='Greys')\n",
        "pred = model.predict(x_test_mnist[image_index].reshape(1, 28, 28, 1))\n",
        "print('The image belongs to the class: ', pred.argmax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_X9Y1sEvCdfs"
      },
      "outputs": [],
      "source": [
        "# plot the training and validation accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UMiPFnVCdfs"
      },
      "outputs": [],
      "source": [
        "# plot the training and validation loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Model\n",
        "model.save('mnist_custom.h5')"
      ],
      "metadata": {
        "id": "VoZjgC3_z0By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question: What can you say about the training of this model by looking at the accuracy and loss plots?"
      ],
      "metadata": {
        "id": "RlSOYnILJNnh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbBEynn-Cdfu"
      },
      "source": [
        "## Ans:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI27d9GuCdfv"
      },
      "source": [
        "### 8. Now Repeat The Steps For The Fashion MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRClaP97Cdfw"
      },
      "outputs": [],
      "source": [
        "# import the Fashion MNIST dataset\n",
        "(x_train_fashion, y_train_fashion), (x_test_fashion, y_test_fashion) = tf.keras.datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHKW2657Cdfw"
      },
      "source": [
        "The dataset has been imported. Use the same approach as above to resize the dataset, build the model, train the model, and evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_e3cTageCdfx"
      },
      "outputs": [],
      "source": [
        "# Resize and Normalize the dataset\n",
        "# Enter Code Here ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpOKnNOCCdfz"
      },
      "outputs": [],
      "source": [
        "# Build the Neural Network Model Architecture\n",
        "# Enter Code Here ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1nkBUdECdf0"
      },
      "outputs": [],
      "source": [
        "# Train the Model\n",
        "# Enter Code Here ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjfLVjBgCdf0"
      },
      "outputs": [],
      "source": [
        "# Evaluate the Model\n",
        "# Enter Code Here ..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Model\n",
        "model.save('fashion_mnist_custom.h5')"
      ],
      "metadata": {
        "id": "f8CCgtuvt0zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYdL2iDWCdf1"
      },
      "source": [
        "## Question: What can you say about the training of this model by looking at the accuracy and loss plots?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieFzqeMbCdf2"
      },
      "source": [
        "## Ans:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ-UTtoBCdf3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdUK2O5kCdf4"
      },
      "source": [
        "### 9. Transfer Learning\n",
        "You must have notices that training your model takes a long time. This is because a model was built and trained from scratch. This means that the model that was created had no prior knowledge and everything was learnt from scratch. Although you obtained high accuracies, this is not always that case due to limited availability of large datasets. Therefore, we introduce the concept of transfer learning. Transfer learning is a technique used for training deep learning models where pre-trained weights are obtained and used as priors for training new models. The pre-trained weights are usually obtained from models that were trained on large datasets with multiple classes. It is not necessary for the pre-trained weights to be obtaine from a model that was trained on the same dataset, nor the same application.\n",
        "\n",
        "Pre-trained weights can be loaded into your custom defined models from part 5 of this lab. However, over the past decade, multiple netowrk architectures have been developed that can used with the pre-trained weights. For this lab, you will be using the VGG16 network architecture as shown below. This network architecture can be easily loaded from the Keras and TensorFlow libraries. \n",
        "\n",
        "<!-- <img src=\"img/vgg.png\" width=500 height=200 /> -->\n",
        "\n",
        "A common dataset that is used for obtain pre-trained weights is the ImageNet dataset. The pre-trained weights are already avaialble from Keras and TensorFlow. In this section, you will be loading pre-trained weights into popular network architectures for training the same models.\n",
        "\n",
        "<!-- <img src=\"img/Imagenet.jpg\" width=500 height=200 /> -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvyBOOIyCdf4"
      },
      "outputs": [],
      "source": [
        "# load the VGG16 model with the ImageNet pre-trained weights\n",
        "tf.keras.applications.VGG16(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "'''\n",
        "You may also load additional Network Architectures:\n",
        "1. ResNet50 architecture: tf.keras.applications.resnet50.ResNet50(...)\n",
        "2. InceptionV3 architecture: tf.keras.applications.inception_v3.InceptionV3(...)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the dataset in 3 dimensions as per Network Architecture Requriments"
      ],
      "metadata": {
        "id": "Ryti18YxJwlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the MNIST dataset\n",
        "(x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "RHfuyFawyg3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fYxU--1Cdf5"
      },
      "outputs": [],
      "source": [
        "# the code below has been provided to you for preparing the dataset\n",
        "# this time, the data needs to be in RGB format rather than greyscale therefore there are additional steps for preparing the dataset\n",
        "x_train_mnist = np.dstack([x_train_mnist] * 3)\n",
        "x_test_mnist = np.dstack([x_test_mnist] * 3)\n",
        "x_train_mnist.shape, x_test_mnist.shape\n",
        "\n",
        "x_train_mnist = x_train_mnist.reshape(-1, 28,28,3)\n",
        "x_test_mnist = x_test_mnist.reshape (-1,28,28,3)\n",
        "x_train_mnist.shape, x_test_mnist.shape\n",
        "\n",
        "x_train_mnist = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in x_train_mnist])\n",
        "x_test_mnist = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in x_test_mnist])\n",
        "#train_x = preprocess_input(x)\n",
        "\n",
        "x_train_mnist.shape, x_test_mnist.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XA2dDzWwCdf_"
      },
      "outputs": [],
      "source": [
        "# load in the custom VGG16 model and build the architecture\n",
        "inp = Input((48, 48, 3))\n",
        "pre_model = tf.keras.applications.VGG16(include_top=False,  # This will exclude the final output layer from the pre-trained VGG16 model as it is comprised of 1000 filters while we need 10 only\n",
        "                                        weights='imagenet',  # This will import the weights from the ImageNet trained model which will essentially help implement Transfer Learning\n",
        "                                        input_tensor=inp,  # This is the input tensor size for the images / data\n",
        "                                        input_shape=(48, 48, 3), # This is the input size for the images / data\n",
        "                                        pooling='max')  # We will train the model using max pooling \n",
        "\n",
        "# show the model summary\n",
        "pre_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1KlEzcpCdgA"
      },
      "outputs": [],
      "source": [
        "# From the summary above, you will noteice that the final layer at the bottom has size 512. We need an additional layer with 10 filters for the 10 classes in the MNIST dataset.\n",
        "\n",
        "# Add a final output Dense Layer with 10 filters and Softmax activation function\n",
        "x = pre_model.output\n",
        "out = Dense(10, activation='softmax')(x)\n",
        "complete_model = Model(inp, out)\n",
        "\n",
        "# show the model summary\n",
        "complete_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxBO4sSCCdgA"
      },
      "outputs": [],
      "source": [
        "# From the summary above, you will notice that the final layer at the bottom now has size 10\n",
        "\n",
        "# make sure that the convolutional base is frozen to use the transfer learning weights from ImageNet\n",
        "for layer in complete_model.layers[:-1]:\n",
        "    layer.trainable=False\n",
        "\n",
        "# show the model summary\n",
        "complete_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrFb4sHICdgB"
      },
      "outputs": [],
      "source": [
        "# compile the pre-trained model\n",
        "complete_model.compile(optimizer='adam',  # We will be using the Adam optimizer. This is useful and has proven effective for multiclass classification problems.\n",
        "              loss='sparse_categorical_crossentropy',  # We will use the categorical crossentropy loss function. The loss function helps the different filters update weights to learn features from data.\n",
        "              metrics=['accuracy'])  # While training the model, this line will hep keep track of the accuracy.\n",
        "\n",
        "# train the pre-trained model\n",
        "history = complete_model.fit(x=x_train_mnist, y=y_train_mnist, batch_size=128, validation_data=(x_test_mnist, y_test_mnist), epochs=10)\n",
        "# x represents the training data\n",
        "# y represnets the training labels\n",
        "# batch size represents the number of images that will be fed into the model at a time (if it increases, training will be faster but it will require more RAM)\n",
        "# validation data requires (testing data, testing labels)\n",
        "# we train the model for 10 epochs which means that the model will go over the entire dataset 10 times to learn and confirm model training performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GQuLzLtCdgB"
      },
      "outputs": [],
      "source": [
        "# plot the training and validation accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eYIHrhPCdgE"
      },
      "outputs": [],
      "source": [
        "# plot the training and validation loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Model\n",
        "complete_model.save('mnist_transfer_learning.h5')"
      ],
      "metadata": {
        "id": "clrOa1ICt6Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7N8xOU3CdgF"
      },
      "source": [
        "## Question: What can you say about the training of this model by looking at the accuracy and loss plots?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3G7WWl5CdgF"
      },
      "source": [
        "## Ans:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fY0wkjRKCdgG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD-sIZI6CdgG"
      },
      "source": [
        "### 10. Now Repeat The Steps For Transfer Learning From Step 9 On The Fashion MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtEQtowKCdgG"
      },
      "outputs": [],
      "source": [
        "# import the Fashion MNIST dataset\n",
        "(x_train_fashion, y_train_fashion), (x_test_fashion, y_test_fashion) = tf.keras.datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PqwuKI5CdgJ"
      },
      "outputs": [],
      "source": [
        "# Resize and Normalize the dataset\n",
        "# Enter Code Here ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QD7lS8FlCdgK"
      },
      "outputs": [],
      "source": [
        "# load the VGG16 model with the ImageNet pre-trained weights\n",
        "# Enter Code Here ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KGve9FYCdgK"
      },
      "outputs": [],
      "source": [
        "# Train the Model\n",
        "# Enter Code Here ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fu7n6mw9CdgL"
      },
      "outputs": [],
      "source": [
        "# Evaluate the Model\n",
        "# Enter Code Here ..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Model\n",
        "complete_model.save('fashion_mnist_transfer_learning.h5')"
      ],
      "metadata": {
        "id": "xRzlv7XIt-bV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}